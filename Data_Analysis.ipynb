{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Car Accident Severity__\n",
    "\n",
    "The objective of the project is to develop an automatic learning model / solution that allows identifying the main factors that affect the severity of an accident. For this, a database is provided that consists of information on the weather, the direction of the vehicles, the type of light that existed in the environment, the number of people involved in the accident, among others.\n",
    "\n",
    "The Target variable is severity, which has the following codes:\n",
    "\n",
    "- 3: Fatal, at least one death.\n",
    "- 2b: Serious Injury\n",
    "- 2: Injury\n",
    "- 1: Prop damage\n",
    "- 0: Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Import Modules__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Cleaning Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data and validating NANS in it. \n",
    "# Si el nÃºmero de datos NAN es mayor al 50 % entonces no es una columna valida. \n",
    "variables = [\n",
    "    \"SEVERITYCODE\", \"X\", \"Y\", \"ADDRTYPE\", \"HITPARKEDCAR\", \"COLLISIONTYPE\", \"PERSONCOUNT\", \"PEDCOUNT\",\n",
    "    \"PEDCYLCOUNT\", \"VEHCOUNT\", \"UNDERINFL\", \"WEATHER\", \"ROADCOND\", \"LIGHTCOND\"\n",
    "]\n",
    "data = pd.read_csv(\"datasets/Data-Collisions.csv\")[variables]\n",
    "valid_columns = []\n",
    "for i in data.columns: \n",
    "    if data[i].isna().sum()/len(data) >0.4: \n",
    "        pass\n",
    "    else: \n",
    "        valid_columns.append(i)\n",
    "        \n",
    "data = data[valid_columns]\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data Engineering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Dummies\n",
    "# Convert Categorical Variables: \n",
    "weather = pd.get_dummies(data.WEATHER)\n",
    "road_con = pd.get_dummies(data.ROADCOND)\n",
    "colicion_d  = pd.get_dummies(data.COLLISIONTYPE)\n",
    "light_d  = pd.get_dummies(data.LIGHTCOND)\n",
    "add_d  = pd.get_dummies(data.ADDRTYPE)\n",
    "\n",
    "\n",
    "data= pd.concat([data, weather], axis = 1)\n",
    "data= pd.concat([data, road_con], axis = 1)\n",
    "data= pd.concat([data, colicion_d], axis = 1)\n",
    "data= pd.concat([data, light_d], axis = 1)\n",
    "data= pd.concat([data, add_d], axis = 1)\n",
    "\n",
    "data[\"HITPARKEDCAR\"] = data[\"HITPARKEDCAR\"].apply(lambda x: 0 if x== \"N\" else 1)\n",
    "\n",
    "variable = []\n",
    "\n",
    "for i in data.UNDERINFL: \n",
    "    if i == \"N\": \n",
    "        variable.append(0)\n",
    "    if i == \"0\": \n",
    "        variable.append(0)\n",
    "    if i == \"1\": \n",
    "        variable.append(1)\n",
    "    if i == \"Y\": \n",
    "        variable.append(1)\n",
    "        \n",
    "data[\"UNDERINFL\"]= variable\n",
    "\n",
    "data.drop(columns = [\"WEATHER\", \"ROADCOND\", \"COLLISIONTYPE\", \"LIGHTCOND\", \"ADDRTYPE\"], inplace =True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"SEVERITYCODE\"]\n",
    "X = data.loc[:, data.columns != 'SEVERITYCODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6942166711919631\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
